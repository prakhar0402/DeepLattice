#!/bin/sh
#SBATCH --partition=gpu
#SBATCH --gres=gpu:2
#SBATCH --time=72:00:00
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=12
##SBATCH --cpus-per-task=1
#SBATCH --constraint=CPU-X5650
#SBATCH --mem=48000
# Memory per node specification is in MB. It is optional. 
# The default limit is 3GB per core.
#SBATCH --job-name="RL_GPU_Run"
#SBATCH --output=results/RL_GPU_Run.out
#SBATCH --mail-user=prakharj@buffalo.edu
#SBATCH --mail-type=END
#SBATCH --requeue
#Specifies that the job will be requeued after a node failure.
#The default is that the job will not be requeued.


echo "SLURM_JOBID="$SLURM_JOBID
echo "SLURM_JOB_NODELIST"=$SLURM_JOB_NODELIST
echo "SLURM_NNODES"=$SLURM_NNODES
echo "SLURMTMPDIR="$SLURMTMPDIR

cd $SLURM_SUBMIT_DIR
echo "working directory = "$SLURM_SUBMIT_DIR

module list
ulimit -s unlimited

echo "Starting job..."

python deepRL.py

echo "All Done!"
